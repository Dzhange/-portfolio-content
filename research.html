<!DOCTYPE html>
<html lang="en">
<!-- All of the meta data for the page belongs in the header tag -->
<head>
	<meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
	<link rel="preconnect" href="https://fonts.googleapis.com">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link href="https://fonts.googleapis.com/css2?family=Indie+Flower&display=swap" rel="stylesheet">
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

	<link rel="stylesheet" type="text/css" href="css/html5reset.css">
    <link rel="stylesheet" type="text/css" href="css/styles.css">
	<title>Research</title>
	<link rel="icon" type="image/png" href="./images/site_icon.png">
</head>

<body>
	<header>
        <nav>
            <ul  class="nav_links">
				<li><i class="fa fa-home"></i>   <a href="index.html">Home</a></li>
				<li><i class="fa fa-camera"></i> <a href="gallery.html">Gallery</a></li>
				<li><i class="fa fa-flask"></i>  <a class="active" href="research.html">Research</a></li>
				<li><i class="fa fa-gear"></i>   <a href="projects.html">Projects</a></li>
			</ul>
		</nav>
	</header>


	<main>
		
		<h1> Research </h1>
		<p>
            Deformable Objects are hard to track, and even harder when they are partially under occlusion due to the ambi-
            guity caused by shape variation cased by interaction with other objects or itself. While existing model-based methods
            didn't explicitly model this ambiguity and only provides only single solution, 
            we proposed a generative model with data-driven method that implies multiple plausible results from single observation. 
            We test our method on a synthetic dataset generated using PyBullet and 
            achieved better results than baseline method. 
            This work has set the foundation for tracking general deformable objects with occlusion.
		</p>
        <figure>
			<img class="pipeline" src="images/deformable_recon.png"  alt="The pipeline of Deformable Objects Reconstruction">
			<figcaption>The pipeline of Deformable Objects Reconstruction</figcaption>
		</figure>

		<p>
            We present StrobeNet, a method for category-level 3D reconstruction of articulating objects from one or more RGB images. 
            Reconstructing general articulating object categories has important applications, 
            but is challenging since objects can have wide variation in shape, appearance and topology. 
            We address this problem by building on the idea of category-level articulation canonicalization 
            mapping object observations to a canonical articulation which enables correspondence-free multiview aggregation. 
            Our endto-end trainable neural network estimates feature-enriched canonical 3D point clouds, articulation joints, and part segmentation from one or more images. 
            These intermediate estimates are used to generate an implicit function as the final shape reconstruction. 
            Our approach can reconstruct objects even when they are observed in different articulations in images with large baselines,
             and allows reconstruction of animatable 3D models of objects. Quantitative and qualitative evaluations on our new benchmark dataset demonstrate that our method is able to achieve high reconstruction accuracy, especially as more views are added.
		</p>
        <figure>
			<img class="pipeline" src="images/strobenet_teaser.png"  alt="The pipeline of StrobeNet" >
			<figcaption>The pipeline of StrobeNet</figcaption>
		</figure>

        <p>
            We present a deformation correction technique called deep body deformation (DBD) to improve realism in skeletal animated human
            characters. We observe despite heterogeneity of shape across the human body, deformations on specific body parts exhibit high coherence due to physiological constraints. 
            We therefore design an autoencoder net-work to encode shape variations and learn deformations unique to each semantically meaningful body part. 
            To enforce deformation consistency over the entire animation sequence, we further develop a temporal en-coding scheme based on LSTM. 
            Compared with the state-of-the-art such as LBS and SMPL, shape deformations produced by our technique are more accurate and appear more natural and preserve rich details.
		</p>
		<figure>
			<img class="pipeline" src="images/dbd_pipeline.png"  alt="The pipeline of Deep Body Deformation" >
			<figcaption>The pipeline of Deep Body Deformation</figcaption>
		</figure>

	</main>

	<footer>
		&copy; 2022
	</footer>
</body>
</html>
